{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test_article\n",
      "Processing DeepSeek_R1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from Mongo import MongoDB\n",
    "from KnowledgeBase import KnowledgeBase\n",
    "\n",
    "kb = KnowledgeBase(config_path=\"rag.yaml\")\n",
    "operations = [\n",
    "    #\"create_knowledge\",\n",
    "    \"refine_knowledge\"\n",
    "    ]\n",
    "if \"create_knowledge\" in operations:\n",
    "    kb.create_knowledge()\n",
    "if \"refine_knowledge\" in operations:\n",
    "    kb.refine_knowledge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = MongoDB(config_path='mongo.yaml')  # Adjust if your path is different\n",
    "collection_name = \"knowledge_base\"\n",
    "operation = \"update\"\n",
    "\n",
    "# Load the refined_kb.json\n",
    "with open('refined_kb.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "if operation == \"insert\":\n",
    "    for doc in data:\n",
    "        if not db.find_one(collection_name, {\"_id\": doc.get(\"_id\")}):\n",
    "            db.insert_one(collection_name, doc)\n",
    "\n",
    "if operation == \"update\":\n",
    "    for doc in data:\n",
    "        if db.find_one(collection_name, {\"_id\": doc.get(\"_id\")}):\n",
    "            db.update_one(collection_name, {\"_id\": doc.get(\"_id\")}, {\"$set\": doc})\n",
    "        else:\n",
    "            db.insert_one(collection_name, doc)\n",
    "\n",
    "if operation == \"delete\":\n",
    "    for doc in data:\n",
    "        if db.find_one(collection_name, {\"_id\": doc.get(\"_id\")}):\n",
    "            db.delete_one(collection_name, {\"_id\": doc.get(\"_id\")})\n",
    "        else:\n",
    "            print(f\"Document with _id {doc.get('_id')} not found for deletion.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self_ref': '#/texts/0',\n",
       " 'parent': '#/body',\n",
       " 'label': 'section_header',\n",
       " 'text_content': 'Comparing Machine Learning Approaches for Table Recognition in Historical Register Books',\n",
       " 'document': 'test_article',\n",
       " 'page': 1,\n",
       " 'bbox': {'l': 108.02,\n",
       "  't': 767.185,\n",
       "  'r': 508.81,\n",
       "  'b': 740.116,\n",
       "  'coord_origin': 'BOTTOMLEFT'},\n",
       " 'title': 'Comparing Machine Learning Approaches for Table Recognition in Historical Register Books',\n",
       " '_id': '150469aa7b879e971616294fafcdce72d8c126325a4c08c233ae8baebb6814bf'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('refined_kb.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('refined_kb.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "from Chunker import Chunker\n",
    "\n",
    "chunker = Chunker()\n",
    "chunked_data = chunker.text_structure_chunking(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TABLE 1: WE USE THE BIESO TAGSET FOR FORMULATING THE ROW DETECTION PROBLEM\n",
      "Headers:\n",
      "category\n",
      "explanation\n",
      "Row:\n",
      "category | explanation\n",
      "TABLE 1: WE USE THE BIESO TAGSET FOR FORMULATING THE ROW DETECTION PROBLEM\n",
      "Headers:\n",
      "category\n",
      "explanation\n",
      "Row:\n",
      "B(eginning) | First line of a cell\n",
      "TABLE 1: WE USE THE BIESO TAGSET FOR FORMULATING THE ROW DETECTION PROBLEM\n",
      "Headers:\n",
      "category\n",
      "explanation\n",
      "Row:\n",
      "I(inside) | Line inside a cell (except first and last)\n",
      "TABLE 1: WE USE THE BIESO TAGSET FOR FORMULATING THE ROW DETECTION PROBLEM\n",
      "Headers:\n",
      "category\n",
      "explanation\n",
      "Row:\n",
      "E(nd) | Last line of a cell\n",
      "TABLE 1: WE USE THE BIESO TAGSET FOR FORMULATING THE ROW DETECTION PROBLEM\n",
      "Headers:\n",
      "category\n",
      "explanation\n",
      "Row:\n",
      "S(ingleton) | Single line of the cell\n",
      "TABLE 1: WE USE THE BIESO TAGSET FOR FORMULATING THE ROW DETECTION PROBLEM\n",
      "Headers:\n",
      "category\n",
      "explanation\n",
      "Row:\n",
      "O(utside) | Outside a table\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "TextLine labels | Frequency\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "B | 9947\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "I | 9023\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "E | 9941\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "S | 8675\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "O | 183\n",
      "TABLE 2: FREQUENCIES OF THE DIFFERENT CLASSES IN OUR DATASET.\n",
      "Headers:\n",
      "TextLine labels\n",
      "Frequency\n",
      "Row:\n",
      "Total lines | 37769\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4 | Avg\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "Logit-standard | 150 | 0.37 | 0.37 | 0.36 | 0.36 | 0.37\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "Logit-1conv | 430 | 0.39 | 0.39 | 0.65 | 0.61 | 0.51\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "GCN | 7893 | 0.76 | 0.75 | 0.76 | 0.70 | 0.74\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "CRF (1500 iter.) | 3645 | 0.95 | 0.92 | 0.92 | 0.89 | 0.92\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "3Layer-10conv- FullStack | 25172 | 0.96 | 0.94 | 0.93 | 0.92 | 0.94\n",
      "TABLE 3: ACCURACY FOR BIESO TAGGING (DATASET1)\n",
      "Headers:\n",
      "Method | #params | Fold 1 | Fold 2 | Fold 3 | Fold 4\n",
      "Avg\n",
      "Row:\n",
      "8Layer-1Conv | 14059 | 0.95 | 0.94 | 0.92 | 0.91 | 0.93\n",
      "TABLE 4: EVALUATION (PRECISION, RECALL, F-1 AND BIESO ACCURACY) FOR TABLE ROW DETECTION (DATASET2)\n",
      "Headers:\n",
      "P | R | F-1 | BIESO ACC\n",
      "Row:\n",
      "Method | P | R | F-1 | BIESO ACC\n",
      "TABLE 4: EVALUATION (PRECISION, RECALL, F-1 AND BIESO ACCURACY) FOR TABLE ROW DETECTION (DATASET2)\n",
      "Headers:\n",
      "P | R | F-1 | BIESO ACC\n",
      "Row:\n",
      "CRF (1500 iterations) | 0.864 | 0.933 | 0.897 | 0.911\n",
      "TABLE 4: EVALUATION (PRECISION, RECALL, F-1 AND BIESO ACCURACY) FOR TABLE ROW DETECTION (DATASET2)\n",
      "Headers:\n",
      "P | R | F-1 | BIESO ACC\n",
      "Row:\n",
      "CRF (100 iterations) | 0.785 | 0.907 | 0.842 | 0.754\n",
      "TABLE 4: EVALUATION (PRECISION, RECALL, F-1 AND BIESO ACCURACY) FOR TABLE ROW DETECTION (DATASET2)\n",
      "Headers:\n",
      "P | R | F-1 | BIESO ACC\n",
      "Row:\n",
      "3Layer-10conv-FullStack | 0.842 | 0.930 | 0.884 | 0.881\n",
      "TABLE 4: EVALUATION (PRECISION, RECALL, F-1 AND BIESO ACCURACY) FOR TABLE ROW DETECTION (DATASET2)\n",
      "Headers:\n",
      "P | R | F-1 | BIESO ACC\n",
      "Row:\n",
      "8Layer-1Conv | 0.856 | 0.932 | 0.892 | 0.890\n",
      "Table 2 | Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "OpenAI-o1-mini | 63.6 | 80.0 | 90.0 | 60.0 | 53.8 | 1820\n",
      "Table 2 | Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "OpenAI-o1-0912 | 74.4 | 83.3 | 94.8 | 77.3 | 63.4 | 1843\n",
      "Table 2 | Comparison of DeepSeek-R1-Zero and OpenAI o1 models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Zero | 71.0 | 86.7 | 95.9 | 73.3 | 50.0 | 1444\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217 | DeepSeek R1\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "Architecture | - | - | MoE | - | - | MoE\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "# Activated Params | - | - | 37B | - | - | 37B\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "# Total Params | - | - | 671B | - | - | 671B\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "MMLU (Pass@1) | 88.3 | 87.2 | 88.5 | 85.2 | 91.8 | 90.8\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "MMLU-Redux (EM) | 88.9 | 88.0 | 89.1 | 86.7 | - | 92.9\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "MMLU-Pro (EM) | 78.0 | 72.6 | 75.9 | 80.3 | - | 84.0\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "DROP (3-shot F1) | 88.3 | 83.7 | 91.6 | 83.9 | 90.2 | 92.2\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "IF-Eval (Prompt Strict) | 86.5 | 84.3 | 86.1 | 84.8 | - | 83.3\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "GPQA Diamond (Pass@1) | 65.0 | 49.9 | 59.1 | 60.0 | 75.7 | 71.5\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "SimpleQA (Correct) | 28.4 | 38.2 | 24.9 | 7.0 | 47.0 | 30.1\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "FRAMES (Acc.) | 72.5 | 80.5 | 73.3 | 76.9 | - | 82.5\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "AlpacaEval2.0 (LC-winrate) | 52.0 | 51.1 | 70.0 | 57.8 | - | 87.6\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "ArenaHard (GPT-4-1106) | 85.2 | 80.4 | 85.5 | 92.0 | - | 92.3\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "LiveCodeBench (Pass@1-COT) | 38.9 | 32.9 | 36.2 | 53.8 | 63.4 | 65.9\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "Codeforces (Percentile) | 20.3 | 23.6 | 58.7 | 93.4 | 96.6 | 96.3\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "Codeforces (Rating) | 717 | 759 | 1134 | 1820 | 2061 | 2029\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "SWE Verified (Resolved) | 50.8 | 38.8 | 42.0 | 41.6 | 48.9 | 49.2\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "Aider-Polyglot (Acc.) | 45.3 | 16.0 | 49.6 | 32.9 | 61.7 | 53.3\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "AIME 2024 (Pass@1) | 16.0 | 9.3 | 39.2 | 63.6 | 79.2 | 79.8\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "MATH-500 (Pass@1) | 78.3 | 74.6 | 90.2 | 90.0 | 96.4 | 97.3\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "CNMO2024 (Pass@1) | 13.1 | 10.8 | 43.2 | 67.6 | - | 78.8\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "CLUEWSC (EM) | 85.4 | 87.9 | 90.9 | 89.9 | - | 92.8\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "C-Eval (EM) | 76.7 | 76.0 | 86.5 | 68.9 | - | 91.8\n",
      "Table 4 | Comparison between DeepSeek-R1 and other representative models.\n",
      "Headers:\n",
      "Benchmark (Metric) | Claude-3.5- Sonnet-1022 | GPT-4o 0513 | DeepSeek V3 | OpenAI o1-mini | OpenAI o1-1217\n",
      "DeepSeek R1\n",
      "Row:\n",
      "C-SimpleQA (Correct) | 55.4 | 58.7 | 68.0 | 40.3 | - | 63.7\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "GPT-4o-0513 | 9.3 | 13.4 | 74.6 | 49.9 | 32.9 | 759\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "Claude-3.5-Sonnet-1022 | 16.0 | 26.7 | 78.3 | 65.0 | 38.9 | 717\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "OpenAI-o1-mini | 63.6 | 80.0 | 90.0 | 60.0 | 53.8 | 1820\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "QwQ-32B-Preview | 50.0 | 60.0 | 90.6 | 54.5 | 41.9 | 1316\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Qwen-1.5B | 28.9 | 52.7 | 83.9 | 33.8 | 16.9 | 954\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Qwen-7B | 55.5 | 83.3 | 92.8 | 49.1 | 37.6 | 1189\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Qwen-14B | 69.7 | 80.0 | 93.9 | 59.1 | 53.1 | 1481\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Qwen-32B | 72.6 | 83.3 | 94.3 | 62.1 | 57.2 | 1691\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Llama-8B | 50.4 | 80.0 | 89.1 | 49.0 | 39.6 | 1205\n",
      "Table 5 | Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.\n",
      "Headers:\n",
      "Model | AIME 2024 | MATH-500 | GPQA Diamond | LiveCode Bench | CodeForces\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1 | rating\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Llama-70B | 70.0 | 86.7 | 94.5 | 65.2 | 57.5 | 1633\n",
      "\n",
      "Headers:\n",
      "AIME 2024 | MATH-500 | GPQADiamond | LiveCodeBench | Model\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1\n",
      "Row:\n",
      "AIME 2024 | MATH-500 | GPQADiamond | LiveCodeBench\n",
      "\n",
      "Headers:\n",
      "AIME 2024 | MATH-500 | GPQADiamond | LiveCodeBench | Model\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1\n",
      "Row:\n",
      "Model | pass@1 | cons@64 | pass@1 | pass@1 | pass@1\n",
      "\n",
      "Headers:\n",
      "AIME 2024 | MATH-500 | GPQADiamond | LiveCodeBench | Model\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1\n",
      "Row:\n",
      "QwQ-32B-Preview | 50.0 | 60.0 | 90.6 | 54.5 | 41.9\n",
      "\n",
      "Headers:\n",
      "AIME 2024 | MATH-500 | GPQADiamond | LiveCodeBench | Model\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1\n",
      "Row:\n",
      "DeepSeek-R1-Zero-Qwen-32B | 47.0 | 60.0 | 91.6 | 55.0 | 40.2\n",
      "\n",
      "Headers:\n",
      "AIME 2024 | MATH-500 | GPQADiamond | LiveCodeBench | Model\n",
      "pass@1 | cons@64 | pass@1 | pass@1 | pass@1\n",
      "Row:\n",
      "DeepSeek-R1-Distill-Qwen-32B | 72.6 | 83.3 | 94.3 | 62.1 | 57.2\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "X. Feng, Z. Wan, M. Wen, S. M. McAleer, Y. Wen, W. Zhang, and J. Wang. Alphazero-like tree-search can guide large language model decoding and training, 2024. URL https: //arxiv.org/abs/2309.17179 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "L. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization, 2022. URL https://arxiv.org/abs/2210.10760 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "A. P. Gema, J. O. J. Leang, G. Hong, A. Devoto, A. C. M. Mancino, R. Saxena, X. He, Y. Zhao, X. Du, M. R. G. Madani, C. Barale, R. McHardy, J. Harris, J. Kaddour, E. van Krieken, and P. Minervini. Are we done with mmlu? CoRR, abs/2406.04127, 2024. URL https://doi.or g/10.48550/arXiv.2406.04127 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Google. Our next-generation model: Gemini 1.5, 2024. URL https://blog.google/techno logy/ai/google-gemini-next-generation-model-february-2024 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Y. He, S. Li, J. Liu, Y. Tan, W. Wang, H. Huang, X. Bu, H. Guo, C. Hu, B. Zheng, et al. Chi- nese simpleqa: A chinese factuality evaluation for large language models. arXiv preprint arXiv:2411.07140, 2024.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Y. Huang, Y. Bai, Z. Zhu, J. Zhang, J. Zhang, T. Su, J. Liu, C. Lv, Y. Zhang, J. Lei, et al. C-Eval: A multi-level multi-discipline chinese evaluation suite for foundation models. arXiv preprint arXiv:2305.08322, 2023.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "N. Jain, K. Han, A. Gu, W. Li, F. Yan, T. Zhang, S. Wang, A. Solar-Lezama, K. Sen, and I. Stoica. Livecodebench: Holistic and contamination free evaluation of large language models for code. CoRR, abs/2403.07974, 2024. URL https://doi.org/10.48550/arXiv.2403.07974 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "S. Krishna, K. Krishna, A. Mohananey, S. Schwarcz, A. Stambler, S. Upadhyay, and M. Faruqui. Fact, fetch, and reason: A unified evaluation of retrieval-augmented generation. CoRR, abs/2409.12941, 2024. doi: 10.48550/ARXIV.2409.12941. URL https://doi.org/10.485 50/arXiv.2409.12941 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "A. Kumar, V. Zhuang, R. Agarwal, Y. Su, J. D. Co-Reyes, A. Singh, K. Baumli, S. Iqbal, C. Bishop, R. Roelofs, et al. Training language models to self-correct via reinforcement learning. arXiv preprint arXiv:2409.12917, 2024.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "H. Li, Y. Zhang, F. Koto, Y. Yang, H. Zhao, Y. Gong, N. Duan, and T. Baldwin. CMMLU: Measur- ing massive multitask language understanding in Chinese. arXiv preprint arXiv:2306.09212, 2023.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "T. Li, W.-L. Chiang, E. Frick, L. Dunlap, T. Wu, B. Zhu, J. E. Gonzalez, and I. Stoica. From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline. arXiv preprint arXiv:2406.11939, 2024.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "H. Lightman, V. Kosaraju, Y. Burda, H. Edwards, B. Baker, T. Lee, J. Leike, J. Schulman, I. Sutskever, and K. Cobbe. Let's verify step by step. arXiv preprint arXiv:2305.20050, 2023.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "B. Y. Lin. ZeroEval: A Unified Framework for Evaluating Language Models, July 2024. URL https://github.com/WildEval/ZeroEval .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "MAA. American invitational mathematics examination - aime. In American Invitational Mathematics Examination - AIME 2024, February 2024. URL https://maa.org/math -competitions/american-invitational-mathematics-examination-aime .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "OpenAI. Hello GPT-4o, 2024a. URL https://openai.com/index/hello-gpt-4o/ .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "OpenAI. Learning to reason with llms, 2024b. URL https://openai.com/index/learnin g-to-reason-with-llms/ .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "OpenAI. Introducing SimpleQA, 2024c. URL https://openai.com/index/introducing -simpleqa/ .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "OpenAI. Introducing SWE-bench verified we're releasing a human-validated subset of swe- bench that more, 2024d. URL https://openai.com/index/introducing-swe-bench -verified/ .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Qwen. Qwq: Reflect deeply on the boundaries of the unknown, 2024a. URL https://qwenlm .github.io/blog/qwq-32b-preview/ .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Qwen. Qwen2.5: Aparty of foundation models, 2024b. URL https://qwenlm.github.io/b log/qwen2.5 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "D. Rein, B. L. Hou, A. C. Stickland, J. Petty, R. Y. Pang, J. Dirani, J. Michael, and S. R. Bowman. GPQA: Agraduate-level google-proof q&a benchmark. arXiv preprint arXiv:2311.12022, 2023.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Z. Shao, P. Wang, Q. Zhu, R. Xu, J. Song, M. Zhang, Y. Li, Y. Wu, and D. Guo. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300, 2024.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "D. Silver, T. Hubert, J. Schrittwieser, I. Antonoglou, M. Lai, A. Guez, M. Lanctot, L. Sifre, D. Kumaran, T. Graepel, T. P. Lillicrap, K. Simonyan, and D. Hassabis. Mastering chess and shogi by self-play with a general reinforcement learning algorithm. CoRR, abs/1712.01815, 2017a. URL http://arxiv.org/abs/1712.01815 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "D. Silver, J. Schrittwieser, K. Simonyan, I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton, Y. Chen, T. P. Lillicrap, F. Hui, L. Sifre, G. van den Driessche, T. Graepel, and D. Hassabis. Mastering the game of go without human knowledge. Nat., 550(7676):354-359, 2017b. doi: 10.1038/NATURE24270. URL https://doi.org/10.1038/nature24270 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "C. Snell, J. Lee, K. Xu, and A. Kumar. Scaling llm test-time compute optimally can be more effective than scaling model parameters, 2024. URL https://arxiv.org/abs/2408.033 14 .\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "T. Trinh, Y. Wu, Q. Le, H. He, and T. Luong. Solving olympiad geometry without human demonstrations. Nature, 2024. doi: 10.1038/s41586-023-06747-5.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "J. Uesato, N. Kushman, R. Kumar, F. Song, N. Siegel, L. Wang, A. Creswell, G. Irving, and I. Higgins. Solving math word problems with process-and outcome-based feedback. arXiv preprint arXiv:2211.14275, 2022.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "P. Wang, L. Li, Z. Shao, R. Xu, D. Dai, Y. Li, D. Chen, Y. Wu, and Z. Sui. Math-shepherd: Alabel- free step-by-step verifier for llms in mathematical reasoning. arXiv preprint arXiv:2312.08935, 2023.\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Core Contributors | Hui Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Daya Guo | Jianzhong Guo\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Dejian Yang | Jiashi Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Haowei Zhang | Jingchang Chen\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Junxiao Song | Jingyang Yuan\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Ruoyu Zhang | Jinhao Tu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Runxin Xu | Junjie Qiu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Qihao Zhu | Junlong Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shirong Ma | J.L. Cai\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Peiyi Wang | Jiaqi Ni\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiao Bi | Jian Liang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaokang Zhang | Jin Chen\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xingkai Yu | Kai Dong\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Yu Wu | Kai Hu*\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Z.F. Wu | Kaichao You\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zhibin Gou | Kaige Gao\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zhihong Shao | Kang Guan\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zhuoshu Li | Kexin Huang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Ziyi Gao | Kuai Yu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Lean Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Contributors | Lecong Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Aixin Liu | Liang Zhao\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Bing Xue | Litong Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Bingxuan Wang | Liyue Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Bochao Wu | Lei Xu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Bei Feng | Leyi Xia\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Chengda Lu | Mingchuan Zhang Minghua Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Chenggang Zhao | Minghui Tang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Chengqi Deng | Mingxu Zhou\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Chong Ruan | Meng Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Damai Dai | Miaojun Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Deli Chen | Mingming Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Dongjie Ji | Ning Tian\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Erhang Li | Panpan Huang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Fangyun Lin Fucong Dai | Peng Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Qiancheng Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Fuli Luo* | Qinyu Chen\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Guangbo Hao | Qiushi Du\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Guanting Chen\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Ruiqi Ge*\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Guowei Li H. Zhang | Ruisong Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Hanwei Xu | Ruizhe Pan\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Honghui Ding | Runji Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Huazuo Gao | R.J. Chen R.L. Jin\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Ruyi Chen | Y.X. Wei\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shanghao Lu | Yang Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shangyan Zhou | Yanhong Xu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shanhuang Chen | Yao Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shengfeng Ye | Yao Zhao\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shiyu Wang | Yaofeng Sun\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shuiping Yu | Yaohui Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shunfeng Zhou | Yi Yu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shuting Pan | Yichao Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "S.S. Li | Yifan Shi\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shuang Zhou | Yiliang Xiong\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shaoqing Wu | Ying He\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Shengfeng Ye | Yishi Piao\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Tao Yun | Yisong Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Tian Pei | Yixuan Tan\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Tianyu Sun | Yiyang Ma*\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "T. Wang | Yiyuan Liu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wangding Zeng | Yongqiang Guo\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wen Liu | Yuan Ou\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wenfeng Liang | Yuduan Wang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wenjun Gao | Yue Gong\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wenqin Yu* | Yuheng Zou\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wentao Zhang | Yujia He\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "W.L. Xiao | Yunfan Xiong\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Wei An | Yuxiang Luo\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaodong Liu | Yuxiang You\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaohan Wang | Yuxuan Liu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaokang Chen | Yuyang Zhou\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaotao Nie | Y.X. Zhu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xin Cheng | Yanping Huang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xin Liu | Yaohui Li\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xin Xie | Yi Zheng\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xingchao Liu | Yuchen Zhu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xinyu Yang | Yunxian Ma\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xinyuan Li | Ying Tang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xuecheng Su | Yukun Zha\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xuheng Lin | Yuting Yan\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "X.Q. Li | Z.Z. Ren\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiangyue Jin | Zehui Ren\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaojin Shen | Zhangli Sha\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaosha Chen | Zhe Fu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaowen Sun | Zhean Xu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xiaoxiang Wang | Zhenda Xie\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xinnan Song | Zhengyan Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xinyi Zhou | Zhewen Hao\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xianzu Wang | Zhicheng Ma\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Xinxia Shan | Zhigang Yan\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Y.K. Li Y.Q. Wang | Zhiyu Wu Zihui Gu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zijia Zhu | Zhen Huang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zijun Liu* | Zhipeng Xu\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zilin Li | Zhongyu Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Ziwei Xie | Zhen Zhang\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Ziyang Song\n",
      "\n",
      "Headers:\n",
      "\n",
      "Row:\n",
      "Zizheng Pan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(c['text_content']) for c in chunked_data if c['label'] == 'table']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: [1]\n",
      "----------------------------------------\n",
      "Page: [1]\n",
      "----------------------------------------\n",
      "Page: [2]\n",
      "----------------------------------------\n",
      "Page: [3]\n",
      "----------------------------------------\n",
      "Page: [3]\n",
      "----------------------------------------\n",
      "Page: [4]\n",
      "----------------------------------------\n",
      "Page: [4]\n",
      "----------------------------------------\n",
      "Page: [4]\n",
      "----------------------------------------\n",
      "Page: [4, 5]\n",
      "----------------------------------------\n",
      "Page: [5]\n",
      "----------------------------------------\n",
      "Page: [5]\n",
      "----------------------------------------\n",
      "Page: [5]\n",
      "----------------------------------------\n",
      "Page: [5, 6]\n",
      "----------------------------------------\n",
      "Page: [6]\n",
      "----------------------------------------\n",
      "Page: [6]\n",
      "----------------------------------------\n",
      "Page: [6, 7]\n",
      "----------------------------------------\n",
      "Page: [7, 8]\n",
      "----------------------------------------\n",
      "Page: [8, 9]\n",
      "----------------------------------------\n",
      "Page: [9]\n",
      "----------------------------------------\n",
      "Page: [9]\n",
      "----------------------------------------\n",
      "Page: [9]\n",
      "----------------------------------------\n",
      "Page: [10]\n",
      "----------------------------------------\n",
      "Page: [10]\n",
      "----------------------------------------\n",
      "Page: [10, 11]\n",
      "----------------------------------------\n",
      "Page: [11]\n",
      "----------------------------------------\n",
      "Page: [11]\n",
      "----------------------------------------\n",
      "Page: [11, 12]\n",
      "----------------------------------------\n",
      "Page: [12]\n",
      "----------------------------------------\n",
      "Page: [12, 13]\n",
      "----------------------------------------\n",
      "Page: [13, 14]\n",
      "----------------------------------------\n",
      "Page: [14]\n",
      "----------------------------------------\n",
      "Page: [14]\n",
      "----------------------------------------\n",
      "Page: [14, 15]\n",
      "----------------------------------------\n",
      "Page: [15]\n",
      "----------------------------------------\n",
      "Page: [15, 16]\n",
      "----------------------------------------\n",
      "Page: [16]\n",
      "----------------------------------------\n",
      "Page: [16]\n",
      "----------------------------------------\n",
      "Page: [16, 17, 18, 19]\n",
      "----------------------------------------\n",
      "Page: [19]\n",
      "----------------------------------------\n",
      "Page: [20]\n",
      "----------------------------------------\n",
      "Page: [20, 21, 22]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunked_data:\n",
    "    print(f\"Page: {chunk['pages']}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': '2.2.1. Reinforcement Learning Algorithm',\n",
       "  'cluster_id': 0,\n",
       "  'text': 'Aconversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>. User: prompt. Assistant:',\n",
       "  'page': 6},\n",
       " {'title': '2.2.1. Reinforcement Learning Algorithm',\n",
       "  'cluster_id': 1,\n",
       "  'text': 'Table 1 | Template for DeepSeek-R1-Zero. prompt will be replaced with the specific reasoning question during training.',\n",
       "  'page': 6},\n",
       " {'title': '2.2.2. Reward Modeling',\n",
       "  'cluster_id': 2,\n",
       "  'text': '2.2.2. Reward Modeling',\n",
       "  'page': 6},\n",
       " {'title': '2.2.2. Reward Modeling',\n",
       "  'cluster_id': 3,\n",
       "  'text': 'The reward is the source of the training signal, which decides the optimization direction of RL. To train DeepSeek-R1-Zero, we adopt a rule-based reward system that mainly consists of two types of rewards:',\n",
       "  'page': 6},\n",
       " {'title': '2.2.2. Reward Modeling',\n",
       "  'cluster_id': 4,\n",
       "  'text': 'We do not apply the outcome or process neural reward model in developing DeepSeek-R1-Zero, because we find that the neural reward model may suffer from reward hacking in the large-scale reinforcement learning process, and retraining the reward model needs additional training resources and it complicates the whole training pipeline.',\n",
       "  'page': 6},\n",
       " {'title': '2.2.3. Training Template',\n",
       "  'cluster_id': 5,\n",
       "  'text': '2.2.3. Training Template',\n",
       "  'page': 6},\n",
       " {'title': '2.2.3. Training Template',\n",
       "  'cluster_id': 6,\n",
       "  'text': \"To train DeepSeek-R1-Zero, we begin by designing a straightforward template that guides the base model to adhere to our specified instructions. As depicted in Table 1, this template requires DeepSeek-R1-Zero to first produce a reasoning process, followed by the final answer. We intentionally limit our constraints to this structural format, avoiding any content-specific biases-such as mandating reflective reasoning or promoting particular problem-solving strategies-to ensure that we can accurately observe the model's natural progression during the reinforcement learning (RL) process.\",\n",
       "  'page': 6},\n",
       " {'title': '2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero',\n",
       "  'cluster_id': 7,\n",
       "  'text': '2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero',\n",
       "  'page': 6},\n",
       " {'title': '2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero',\n",
       "  'cluster_id': 8,\n",
       "  'text': \"Performance of DeepSeek-R1-Zero Figure 2 depicts the performance trajectory of DeepSeekR1-Zero on the AIME 2024 benchmark throughout the reinforcement learning (RL) training process. As illustrated, DeepSeek-R1-Zero demonstrates a steady and consistent enhancement in performance as the RL training advances. Notably, the average pass@1 score on AIME 2024 shows a significant increase, jumping from an initial 15.6% to an impressive 71.0%, reaching performance levels comparable to OpenAI-o1-0912. This significant improvement highlights the efficacy of our RL algorithm in optimizing the model's performance over time.\",\n",
       "  'page': 6},\n",
       " {'title': '2.2.4. Performance, Self-evolution Process and Aha Moment of DeepSeek-R1-Zero',\n",
       "  'cluster_id': 9,\n",
       "  'text': \"Table 2 provides a comparative analysis between DeepSeek-R1-Zero and OpenAI's o1-0912 models across a variety of reasoning-related benchmarks. The findings reveal that RL empowers\",\n",
       "  'page': 6}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_1_elem = [d for d in data if d[\"page\"] == 6]\n",
    "page_1_elem = filter_elements(page_1_elem)\n",
    "cluster_and_chunk(page_1_elem, eps=30.0, min_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import smolvlm_picture_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PictureDescriptionVlmOptions(batch_size=8, scale=2, picture_area_threshold=0.05, repo_id='HuggingFaceTB/SmolVLM-256M-Instruct', prompt='Describe this image in a few sentences.', generation_config={'max_new_tokens': 200, 'do_sample': False})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smolvlm_picture_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     17\u001b[39m pipeline_options.generate_picture_images = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     19\u001b[39m converter = DocumentConverter(\n\u001b[32m     20\u001b[39m     format_options={\n\u001b[32m     21\u001b[39m         InputFormat.PDF: PdfFormatOption(\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     }\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m doc = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/Users/federico/Dev/Ragu/input/DeepSeek_R1.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.document\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/document_converter.py:220\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    211\u001b[39m ) -> ConversionResult:\n\u001b[32m    212\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    213\u001b[39m         source=[source],\n\u001b[32m    214\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m         page_range=page_range,\n\u001b[32m    219\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/document_converter.py:243\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    240\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    242\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/document_converter.py:278\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    269\u001b[39m _log.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGoing to convert document batch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    271\u001b[39m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/document_converter.py:324\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    320\u001b[39m valid = (\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    322\u001b[39m )\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    326\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/document_converter.py:345\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_pipeline\u001b[39m(\n\u001b[32m    342\u001b[39m     \u001b[38;5;28mself\u001b[39m, in_doc: InputDocument, raises_on_error: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    343\u001b[39m ) -> ConversionResult:\n\u001b[32m    344\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m in_doc.valid:\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m         pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    347\u001b[39m             conv_res = pipeline.execute(in_doc, raises_on_error=raises_on_error)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/document_converter.py:307\u001b[39m, in \u001b[36mDocumentConverter._get_pipeline\u001b[39m\u001b[34m(self, doc_format)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_pipelines:\n\u001b[32m    304\u001b[39m     _log.info(\n\u001b[32m    305\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitializing pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialized_pipelines[cache_key] = \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_options\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    311\u001b[39m     _log.debug(\n\u001b[32m    312\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReusing cached pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/pipeline/standard_pdf_pipeline.py:96\u001b[39m, in \u001b[36mStandardPdfPipeline.__init__\u001b[39m\u001b[34m(self, pipeline_options)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m.build_pipe = [\n\u001b[32m     69\u001b[39m     \u001b[38;5;66;03m# Pre-processing\u001b[39;00m\n\u001b[32m     70\u001b[39m     PagePreprocessingModel(\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m     PageAssembleModel(options=PageAssembleOptions()),\n\u001b[32m     92\u001b[39m ]\n\u001b[32m     94\u001b[39m \u001b[38;5;66;03m# Picture description model\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     picture_description_model := \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_picture_description_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_path\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m ) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe specified picture description kind is not supported: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_options.picture_description_options.kind\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    104\u001b[39m \u001b[38;5;28mself\u001b[39m.enrichment_pipe = [\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# Code Formula Enrichment Model\u001b[39;00m\n\u001b[32m    106\u001b[39m     CodeFormulaModel(\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     picture_description_model,\n\u001b[32m    125\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/pipeline/standard_pdf_pipeline.py:166\u001b[39m, in \u001b[36mStandardPdfPipeline.get_picture_description_model\u001b[39m\u001b[34m(self, artifacts_path)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_picture_description_model\u001b[39m(\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mself\u001b[39m, artifacts_path: Optional[Path] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    162\u001b[39m ) -> Optional[PictureDescriptionBaseModel]:\n\u001b[32m    163\u001b[39m     factory = get_picture_description_factory(\n\u001b[32m    164\u001b[39m         allow_external_plugins=\u001b[38;5;28mself\u001b[39m.pipeline_options.allow_external_plugins\n\u001b[32m    165\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpicture_description_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_picture_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable_remote_services\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_remote_services\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/models/factories/base_factory.py:57\u001b[39m, in \u001b[36mBaseFactory.create_instance\u001b[39m\u001b[34m(self, options, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     56\u001b[39m     _cls = \u001b[38;5;28mself\u001b[39m._classes[\u001b[38;5;28mtype\u001b[39m(options)]\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mself\u001b[39m._err_msg_on_class_not_found(options.kind))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/models/picture_description_vlm_model.py:41\u001b[39m, in \u001b[36mPictureDescriptionVlmModel.__init__\u001b[39m\u001b[34m(self, enabled, enable_remote_services, artifacts_path, options, accelerator_options)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.enabled:\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artifacts_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         artifacts_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     43\u001b[39m         artifacts_path = Path(artifacts_path) / \u001b[38;5;28mself\u001b[39m.options.repo_cache_folder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/docling/models/picture_description_vlm_model.py:79\u001b[39m, in \u001b[36mPictureDescriptionVlmModel.download_models\u001b[39m\u001b[34m(repo_id, local_dir, force, progress)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m progress:\n\u001b[32m     78\u001b[39m     disable_progress_bars()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m download_path = \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Path(download_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py:296\u001b[39m, in \u001b[36msnapshot_download\u001b[39m\u001b[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[39m\n\u001b[32m    294\u001b[39m         _inner_hf_hub_download(file)\n\u001b[32m    295\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m296\u001b[39m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFetching \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os.path.realpath(local_dir))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                       initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Ragu/test-env/lib/python3.11/site-packages/tqdm/std.py:1169\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[32m    618\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs.pop(), end_time - time.monotonic())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    319\u001b[39m         fut.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:451\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__get_result()\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_condition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import smolvlm_picture_description\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_picture_description = True\n",
    "pipeline_options.picture_description_options = (\n",
    "    smolvlm_picture_description \n",
    ")\n",
    "pipeline_options.picture_description_options.prompt = (\n",
    "    \"Describe the image in three sentences. Be consise and accurate.\"\n",
    ")\n",
    "pipeline_options.images_scale = 2.0\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "doc = converter.convert(\"/Users/federico/Dev/Ragu/input/DeepSeek_R1.pdf\").document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
